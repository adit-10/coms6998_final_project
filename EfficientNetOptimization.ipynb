{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18886f9",
   "metadata": {},
   "source": [
    "# EfficientNet Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f34de",
   "metadata": {},
   "source": [
    "#### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b58d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84033890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231efea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, MobileNet, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = preprocess_input(x_train)\n",
    "x_test = preprocess_input(x_test)\n",
    "y_train = np_utils.to_categorical(y_train, 100)\n",
    "y_test = np_utils.to_categorical(y_test, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a8578",
   "metadata": {},
   "source": [
    "#### Create functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    efficientNet_imagenet_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "\n",
    "    #Flatten output layer of Resnet\n",
    "    gfp = GlobalAveragePooling2D()(efficientNet_imagenet_model.output)\n",
    "\n",
    "    #flattened = tf.keras.layers.Flatten()(resnet50_imagenet_model.output)\n",
    "\n",
    "    #Fully connected layer 1\n",
    "    fc1 = Dense(256, activation='relu', name=\"AddedDense1\")(gfp)\n",
    "\n",
    "    #Fully connected layer, output layer\n",
    "    fc2 = Dense(100, activation='softmax', name=\"AddedDense2\")(fc1)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=efficientNet_imagenet_model.input, outputs=fc2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa24a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38116da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894cb7f",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10ca85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=25, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3c398",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe3949",
   "metadata": {},
   "source": [
    "#### Convert model to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd30de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55666e99",
   "metadata": {},
   "source": [
    "#### Dynamic range quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_dynamic_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc004813",
   "metadata": {},
   "source": [
    "#### Full integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f89186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_full_integer_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbf670",
   "metadata": {},
   "source": [
    "#### Float 16 quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a46316",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model_float16_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"/tmp/cifar100_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"cifar100_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_dynamic_quant_file = tflite_models_dir/\"cifar100_tflite_model_dynamic_quant.tflite\"\n",
    "tflite_model_dynamic_quant_file.write_bytes(tflite_model_dynamic_quant)\n",
    "# Save the quantized model:\n",
    "tflite_model_full_integer_quant_file = tflite_models_dir/\"cifar100_tflite_model_full_integer_quant.tflite\"\n",
    "tflite_model_full_integer_quant_file.write_bytes(tflite_model_full_integer_quant)\n",
    "# Save the quantized model:\n",
    "tflite_model_float16_quant_file = tflite_models_dir/\"cifar100_tflite_model_float16_quant.tflite\"\n",
    "tflite_model_float16_quant_file.write_bytes(tflite_model_float16_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a333d51",
   "metadata": {},
   "source": [
    "#### Check tflite model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/cifar100_tflite_models/ -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = preprocess_input(x_train)\n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4050ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_train\n",
    "test_labels = y_train[:,0]\n",
    "y_test = y_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cbb967",
   "metadata": {},
   "source": [
    "#### Quantized model evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1982583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "    global test_images\n",
    "\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "    for i, test_image_index in enumerate(test_image_indices):\n",
    "    #print(i)\n",
    "        test_image = x_test[test_image_index]\n",
    "        test_label = y_test[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "        predictions[i] = output.argmax()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check change in accuracy\n",
    "\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "    global x_test\n",
    "    global y_test\n",
    "\n",
    "    test_image_indices = range(x_test.shape[0])\n",
    "    predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "    #print(predictions)\n",
    "\n",
    "    accuracy = (np.sum(y_test== predictions) * 100) / len(x_test)\n",
    "\n",
    "    print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tflite_model = evaluate_model(tflite_model_file, model_type=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89637c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_dynamic_quant_accuracy = evaluate_model(tflite_model_dynamic_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7720c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_full_integer_quant_accuracy = evaluate_model(tflite_model_full_integer_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07880448",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_float16_quant_accuracy = evaluate_model(tflite_model_float16_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc74d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/cifar100_tflite_models/ -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8848788",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ff2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8eee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = preprocess_input(x_train)\n",
    "x_test = preprocess_input(x_test)\n",
    "y_train = np_utils.to_categorical(y_train, 100)\n",
    "y_test = np_utils.to_categorical(y_test, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53841f3c",
   "metadata": {},
   "source": [
    "#### Check baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, ps)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = x_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd6587",
   "metadata": {},
   "source": [
    "#### Pruning at 0.2 Sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918b7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, ps)\n",
    "    return layer\n",
    "\n",
    "ps = pruning_schedule.PolynomialDecay(\n",
    "                 initial_sparsity=0.20, final_sparsity=0.20,\n",
    "                       begin_step=0, end_step=end_step, frequency=100)\n",
    "\n",
    "model_for_pruning_2 = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e4642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_for_pruning_2.fit(x_train, y_train, batch_size=64, epochs=6, validation_data=(x_test, y_test), callbacks = [pruning_callbacks.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export_2 = tfmot.sparsity.keras.strip_pruning(model_for_pruning_2)\n",
    "_, pruned_keras_file_2 = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export_2, pruned_keras_file_2, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b79864",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export_2)\n",
    "pruned_tflite_model_2 = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file_2 = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file_2, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_2)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file_2)\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b97d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_for_pruning_2_accuracy = model_for_pruning_2.evaluate(\n",
    "   x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned at 0.2 Sparsity test accuracy:', model_for_pruning_2_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12711b29",
   "metadata": {},
   "source": [
    "#### Pruning at 0.4 Sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c277915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, ps)\n",
    "    return layer\n",
    "\n",
    "ps = pruning_schedule.PolynomialDecay(\n",
    "                 initial_sparsity=0.40, final_sparsity=0.40,\n",
    "                       begin_step=0, end_step=end_step, frequency=100)\n",
    "\n",
    "model_for_pruning_4 = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning_4.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2861a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_for_pruning_4.fit(x_train, y_train, batch_size=64, epochs=6, validation_data=(x_test, y_test), callbacks = [pruning_callbacks.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b73893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export_4 = tfmot.sparsity.keras.strip_pruning(model_for_pruning_4)\n",
    "_, pruned_keras_file_4 = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export_4, pruned_keras_file_4, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e919aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_for_pruning_4_accuracy = model_for_pruning_4.evaluate(\n",
    "   x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned at 0.2 Sparsity test accuracy:', model_for_pruning_2_accuracy)\n",
    "print('Pruned at 0.4 Sparsity test accuracy:', model_for_pruning_4_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export_4)\n",
    "pruned_tflite_model_4 = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file_4 = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file_4, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_4)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file_4)\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_2)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83548464",
   "metadata": {},
   "source": [
    "#### Pruning at 0.6 Sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72909c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, ps)\n",
    "    return layer\n",
    "\n",
    "ps = pruning_schedule.PolynomialDecay(\n",
    "                 initial_sparsity=0.60, final_sparsity=0.60,\n",
    "                       begin_step=0, end_step=end_step, frequency=100)\n",
    "\n",
    "model_for_pruning_6 = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning_6.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc4b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_for_pruning_6.fit(x_train, y_train, batch_size=64, epochs=6, validation_data=(x_test, y_test), callbacks = [pruning_callbacks.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80410f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export_6 = tfmot.sparsity.keras.strip_pruning(model_for_pruning_6)\n",
    "_, pruned_keras_file_6 = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export_6, pruned_keras_file_6, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export_6)\n",
    "pruned_tflite_model_6 = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file_6 = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file_6, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_6)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file_6)\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_2)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_4)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_for_pruning_6_accuracy = model_for_pruning_6.evaluate(\n",
    "   x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned at 0.2 Sparsity test accuracy:', model_for_pruning_2_accuracy)\n",
    "print('Pruned at 0.4 Sparsity test accuracy:', model_for_pruning_4_accuracy)\n",
    "print('Pruned at 0.6 Sparsity test accuracy:', model_for_pruning_6_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd41ed8",
   "metadata": {},
   "source": [
    "#### Pruning at 0.8 Sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687b97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense) or isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, ps)\n",
    "    return layer\n",
    "\n",
    "ps = pruning_schedule.PolynomialDecay(\n",
    "                 initial_sparsity=0.80, final_sparsity=0.80,\n",
    "                       begin_step=0, end_step=end_step, frequency=100)\n",
    "\n",
    "model_for_pruning_8 = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning_8.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa16d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_for_pruning_8.fit(x_train, y_train, batch_size=64, epochs=6, validation_data=(x_test, y_test), callbacks = [pruning_callbacks.UpdatePruningStep()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model_for_pruning_8_accuracy = model_for_pruning_8.evaluate(\n",
    "   x_test, y_test, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned at 0.2 Sparsity test accuracy:', model_for_pruning_2_accuracy)\n",
    "print('Pruned at 0.4 Sparsity test accuracy:', model_for_pruning_4_accuracy)\n",
    "print('Pruned at 0.6 Sparsity test accuracy:', model_for_pruning_6_accuracy)\n",
    "print('Pruned at 0.8 Sparsity test accuracy:', model_for_pruning_8_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export_8 = tfmot.sparsity.keras.strip_pruning(model_for_pruning_8)\n",
    "_, pruned_keras_file_8 = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export_8, pruned_keras_file_8, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export_8)\n",
    "pruned_tflite_model_8 = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file_8 = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file_8, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_8)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file_8)\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_2)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_4)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_6)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bd8cb",
   "metadata": {},
   "source": [
    "### Pruning and Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab79145",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export_6)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_2)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_4)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_6)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file_8)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9293d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "    prediction_digits = []\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "    for i, test_image in enumerate(x_test):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == y_test).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c859426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
